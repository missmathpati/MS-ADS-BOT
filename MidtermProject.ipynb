{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b46383-3fae-4960-8c8e-4644183551a3",
   "metadata": {},
   "source": [
    "### Midterm Project\n",
    "### Chatbot for University of Chicago Applied Data Science Program Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1101adb-c9d3-4544-b26b-57bd5e5194f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (1.0.2)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (1.0.0)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.0)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.7.1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n",
      "Downloading langchain-1.0.4-py3-none-any.whl (93 kB)\n",
      "Downloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
      "Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: langgraph-prebuilt, langgraph, langchain\n",
      "\u001b[2K  Attempting uninstall: langgraph-prebuilt\n",
      "\u001b[2K    Found existing installation: langgraph-prebuilt 1.0.1\n",
      "\u001b[2K    Uninstalling langgraph-prebuilt-1.0.1:\n",
      "\u001b[2K      Successfully uninstalled langgraph-prebuilt-1.0.1\n",
      "\u001b[2K  Attempting uninstall: langgraph\n",
      "\u001b[2K    Found existing installation: langgraph 1.0.1\n",
      "\u001b[2K    Uninstalling langgraph-1.0.1:\n",
      "\u001b[2K      Successfully uninstalled langgraph-1.0.1\n",
      "\u001b[2K  Attempting uninstall: langchain\n",
      "\u001b[2K    Found existing installation: langchain 1.0.2\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [langchain]\n",
      "\u001b[2K    Uninstalling langchain-1.0.2:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [langchain]\n",
      "\u001b[2K      Successfully uninstalled langchain-1.0.290m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [langchain]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain]0m [langchain]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-cohere 0.4.6 requires langchain-core<0.4.0,>=0.3.76, but you have langchain-core 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-1.0.4 langgraph-1.0.2 langgraph-prebuilt-1.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18375ffd-0825-47e1-9ecd-086055beffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports & configs\n",
    "import os, re, time, glob, uuid, urllib.parse, json, textwrap, requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# prompting for openAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"enter your key here\")  # set in your env before running\n",
    "\n",
    "# creating folders for raw links, text from links, and the FAISS indexes\n",
    "DATA_DIR = \"msads_data\"\n",
    "HTML_DIR = f\"{DATA_DIR}/html\"\n",
    "TEXT_DIR = f\"{DATA_DIR}/text\"\n",
    "INDEX_DIR = f\"{DATA_DIR}/index\"\n",
    "os.makedirs(HTML_DIR, exist_ok=True)\n",
    "os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "# defaults for the model\n",
    "EMBED_MODEL = \"text-embedding-3-small\"   \n",
    "CHAT_MODEL  = \"gpt-4o-mini\"              \n",
    "K_RETRIEVE  = 5\n",
    "CHUNK_SIZE  = 1000\n",
    "CHUNK_OVERLAP = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00af54b5-6c97-4404-86d9-26d8da001e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/in-person-program/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/online-program/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/capstone-projects/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/course-progressions/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/how-to-apply/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/events-deadlines/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/our-students/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/\n",
      "Saved: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/faqs/\n",
      "10 pages saved in msads_data/html\n"
     ]
    }
   ],
   "source": [
    "# download MS-ADS pages\n",
    "\n",
    "SEED = \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\"\n",
    "\n",
    "TARGET_URLS = [\n",
    "    SEED,\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/in-person-program/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/online-program/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/capstone-projects/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/course-progressions/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/how-to-apply/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/events-deadlines/\",\n",
    "    # \"https://datascience.uchicago.edu/education/ms-in-applied-data-science/tuition-fees-aid/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/our-students/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/\",\n",
    "    \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/faqs/\",\n",
    "]\n",
    "\n",
    "def download_all(urls=TARGET_URLS, out_dir=HTML_DIR, throttle=0.3):\n",
    "    \"\"\"\n",
    "    Downloads each page in TARGET_URLS and saves raw HTML into HTML_DIR.\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"UChicago-MSADS-RAG (class project)\"}\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for url in TARGET_URLS:\n",
    "        try:\n",
    "            resp = requests.get(url, headers=headers, timeout=20)\n",
    "            resp.raise_for_status()\n",
    "            fname = urllib.parse.quote(url, safe=\"\") + \".html\"\n",
    "            with open(os.path.join(out_dir, fname), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(resp.text)\n",
    "            print(f\"Saved: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Skipped {url}: {e}\")\n",
    "\n",
    "    print(f\"{len(urls)} pages saved in {out_dir}\")\n",
    "\n",
    "# Run the fixed-list downloader\n",
    "download_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2a0472e-1df3-400a-a630-2d455d26848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: 10 files\n"
     ]
    }
   ],
   "source": [
    "# clean & normalize the text\n",
    "# remove parts of the HMTL page before extracting text\n",
    "DROP_SELECTORS = [\"nav\", \"footer\", \".site-footer\", \".menu\", \".breadcrumbs\", \"script\", \"style\"]\n",
    "\n",
    "# this helper function finds things like navigation bars, footers, menus, etc.\n",
    "# and removes them from the HTML tree\n",
    "def clean_to_text(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for sel in DROP_SELECTORS:\n",
    "        for tag in soup.select(sel): \n",
    "            tag.decompose()\n",
    "    text = soup.get_text(\"\\n\")\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text).strip()\n",
    "    return text\n",
    "\n",
    "# looks in HTML_DIR folder at each HTML page downloaded, loads the file,\n",
    "# passes it to clean_to_text, writes a .txt file into TEXT_DIR folder\n",
    "def run_clean(in_dir=HTML_DIR, out_dir=TEXT_DIR):\n",
    "    for fn in glob.glob(f\"{in_dir}/*.html\"):\n",
    "        with open(fn, \"r\", encoding=\"utf-8\") as f:\n",
    "            html = f.read()\n",
    "        txt = clean_to_text(html)\n",
    "        base = os.path.basename(fn).replace(\".html\", \"\")\n",
    "        with open(f\"{out_dir}/{base}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(txt)\n",
    "    print(\"Cleaned:\", len(glob.glob(f'{out_dir}/*.txt')), \"files\")\n",
    "\n",
    "run_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29443b3d-add3-4e86-a0c2-7a14ede166d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built Chroma index with 307 chunks at msads_data/index/chroma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/_xzwcqns6vj35vgt26hxm7qh0000gn/T/ipykernel_72047/76826348.py:45: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vs.persist()\n"
     ]
    }
   ],
   "source": [
    "# build Chroma\n",
    "from pathlib import Path\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "def load_docs(txt_dir=TEXT_DIR):\n",
    "    docs = []\n",
    "    for path in glob.glob(f\"{txt_dir}/*.txt\"):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        # recover URL from filename\n",
    "        url = urllib.parse.unquote(os.path.basename(path).replace(\".txt\",\"\").replace(\"%2F\",\"/\"))\n",
    "        # modest section labeling improves retrieval score\n",
    "        docs.append({\"text\": text, \"source\": url})\n",
    "    return docs\n",
    "\n",
    "def chunk_docs(docs):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP, separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    "    )\n",
    "    texts, metas = [], []\n",
    "    for d in docs:\n",
    "        parts = splitter.split_text(d[\"text\"])\n",
    "        for i, p in enumerate(parts):\n",
    "            texts.append(p)\n",
    "            metas.append({\"source\": d[\"source\"], \"chunk_id\": i})\n",
    "    return texts, metas\n",
    "\n",
    "\n",
    "PERSIST_DIR = f\"{INDEX_DIR}/chroma\"\n",
    "Path(PERSIST_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def build_chroma():\n",
    "    docs = load_docs()\n",
    "    texts, metas = chunk_docs(docs)\n",
    "    if not texts:\n",
    "        raise RuntimeError(\"No chunks created — rerun cleaning or lower filters.\")\n",
    "    embeddings = OpenAIEmbeddings(model=EMBED_MODEL)\n",
    "    vs = Chroma.from_texts(\n",
    "        texts=texts,\n",
    "        embedding=embeddings,\n",
    "        metadatas=metas,\n",
    "        persist_directory=PERSIST_DIR,\n",
    "        collection_name=\"msads_msads\"\n",
    "    )\n",
    "    vs.persist()\n",
    "    print(f\"Built Chroma index with {len(texts)} chunks at {PERSIST_DIR}\")\n",
    "\n",
    "build_chroma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ff2c93-27ea-4b58-afff-2deed0834b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personally Identifiable Information scrubbers (saftey add-on in the instructions)\n",
    "# we are removing email addresses (this gibberish looking pattern is coding for emails like mo.abdelhamid@uchicago.edu\n",
    "EMAIL_RE = re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\")\n",
    "# and removing phone numbers (this pattern matches phone numbers in many formats)\n",
    "PHONE_RE = re.compile(r\"\\+?\\d[\\d\\-\\(\\) ]{7,}\\d\")\n",
    "\n",
    "def redact_pii(s: str) -> str:\n",
    "    s = EMAIL_RE.sub(\"[REDACTED_EMAIL]\", s)\n",
    "    s = PHONE_RE.sub(\"[REDACTED_PHONE]\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3406c5e9-08ca-4cfc-8805-4e989363f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grounding prompt we have used before\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant for the University of Chicago MS in Applied Data Science.\n",
    "Answer ONLY using the provided context. If the answer is not in the context, say\n",
    "'I don’t know based on the official MS-ADS pages I have.' Keep answers concise,\n",
    "quote or paraphrase key lines, and include source URLs.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT = \"\"\"Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Rules:\n",
    "- Do not invent program details or deadlines.\n",
    "- Prefer bullet points for lists.\n",
    "- End with 'Sources:' and list the source URLs you used.\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", SYSTEM_PROMPT), (\"human\", HUMAN_PROMPT)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91da3340-db4c-4b56-b880-0f78854be407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/_xzwcqns6vj35vgt26hxm7qh0000gn/T/ipykernel_72047/2089976590.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vs = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# retriever + multi-query expansion\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# loading embeddings and vector store\n",
    "# chose OpenAIEmbeddings model and Chroma vector database\n",
    "emb = OpenAIEmbeddings(model=EMBED_MODEL)\n",
    "vs = Chroma(\n",
    "    persist_directory=PERSIST_DIR,\n",
    "    embedding_function=emb,\n",
    "    collection_name=\"msads_msads\"\n",
    ")\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": K_RETRIEVE})\n",
    "\n",
    "# this is a multi-query element. if someone says \"tell me about the capstone\"\n",
    "# the LLM will decompose it into three related queries before responding\n",
    "# temperature of 0 makes it deterministic, giving same responses every time\n",
    "llm_qt = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
    "\n",
    "# this prompts GPT-4 to use the original question and turn it into 3 related queries\n",
    "QT_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You rewrite questions into diverse, relevant search queries for semantic retrieval.\"),\n",
    "    (\"human\", \"Rewrite the user question into 3 diverse, concise search queries focused on MS-ADS site.\\n\\nQuestion: {q}\")\n",
    "])\n",
    "\n",
    "# user asks a question, q, it's turned into plain text\n",
    "# 'lines' removes bullets or blank lines from the model's ouput\n",
    "def multi_query(q: str):\n",
    "    out = llm_qt.invoke(QT_PROMPT.format_messages(q=q))\n",
    "    lines = [l.strip(\"-• \").strip() for l in out.content.split(\"\\n\") if l.strip()]\n",
    "    # if the model doesn't generate two distinct queries, it just rewrites the original query three times\n",
    "    if len(lines) < 2:\n",
    "        lines = [q, f\"What is {q} (MS-ADS)?\", f\"Details about {q} on MS-ADS\"]\n",
    "        # multi_query() takes one user question and gives back three phrased variations of it\n",
    "    return lines[:3]\n",
    "\n",
    "# this retrieves documents for all query variants\n",
    "\n",
    "def retrieve_with_qt(q: str, k=K_RETRIEVE):\n",
    "    queries = multi_query(q)\n",
    "    # blank array for relevant queries\n",
    "    hits = []\n",
    "    # mq represents each rewritten query\n",
    "    for mq in queries:\n",
    "        # retriever fetches relevant chunks 'docs' from FAISS index\n",
    "        docs = retriever.invoke(mq) or []\n",
    "        # relevant chunks added to hits\n",
    "        hits.extend(docs)\n",
    "    # duplicates removed\n",
    "    seen = set(); uniq = []\n",
    "    for h in hits:\n",
    "        key = (h.metadata.get(\"source\",\"\"), h.metadata.get(\"chunk_id\",-1))\n",
    "        if key not in seen:\n",
    "            seen.add(key); uniq.append(h)\n",
    "        if len(uniq) >= k:\n",
    "            break\n",
    "    return uniq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f7243c4-877f-4c22-88b3-aa65450f4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a list of retrieved document objects and converts them into\n",
    "# one long formatted text string that the language model can read easily.\n",
    "# Each document is labeled with its source URL and separated by \"---\".\n",
    "# The redact_pii function removes any personal information such as emails or phone numbers.\n",
    "def format_docs(docs):\n",
    "    blocks = []\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\",\"\")\n",
    "        blocks.append(f\"[Source: {src}]\\n{redact_pii(d.page_content)}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(blocks)\n",
    "\n",
    "# This line initializes the GPT-4 model that will generate the final answer text\n",
    "llm = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
    "\n",
    "# The build_chain function constructs the RAG pipeline.\n",
    "# It defines how a user question is processed from start to finish: \n",
    "# retrieve documents, prepare context, prompt the model, and parse the result\n",
    "def build_chain():\n",
    "    # The inner function _retrieve handles the retrieval step for one user input.\n",
    "    # It cleans the question of any personal data, retrieves the top matching documents,\n",
    "    # and returns a dictionary that includes the question, the formatted context text, and the documents themselves\n",
    "    def _retrieve(inputs):\n",
    "        q = redact_pii(inputs[\"question\"]) # no PII\n",
    "        docs = retrieve_with_qt(q, k=K_RETRIEVE) # multi query retrieval for relevant docs\n",
    "        return {\"question\": q, \"context\": format_docs(docs), \"docs\": docs} #package docs into dictionary\n",
    "\n",
    "    # RunnablePassthrough passes the input question through, _retrieve fetches and formats context for that question,\n",
    "    # rag_prompt builds the final prompt that includes both question and context, llm generates the answer from the prompt,\n",
    "    # StrOutputParser extracts the text content of the model’s response\n",
    "    chain = (\n",
    "        RunnablePassthrough.assign(**{\"question\": lambda x: x[\"question\"]})\n",
    "        | _retrieve\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "rag_chain = build_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7d70c39-128c-46a3-9a0b-1f488b6f40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function answers a user's question using the pipleline checks for missing sources or \n",
    "# empty results to prevent hallucinated answers\n",
    "def answer(question: str):\n",
    "    # Retrieve relevant documents based on the question\n",
    "    docs = retrieve_with_qt(question, k=K_RETRIEVE)\n",
    "    # Format the retrieved documents into readable context for the model\n",
    "    ctx = format_docs(docs)\n",
    "    # Build the final prompt by inserting the question and context into the template\n",
    "    msg = rag_prompt.format(question=redact_pii(question), context=ctx)\n",
    "    # Send the prompt to the language model and get the generated text\n",
    "    out = llm.invoke(msg).content\n",
    "\n",
    "    #  # If the model forgets to include a \"Sources:\" section, add one manually\n",
    "    urls = list({d.metadata.get(\"source\",\"\") for d in docs if d.metadata.get(\"source\")})\n",
    "    urls = [u if u.startswith(\"http\") else urllib.parse.unquote(u) for u in urls]\n",
    "    if \"Sources:\" not in out:\n",
    "        out += \"\\n\\nSources:\\n\" + \"\\n\".join(urls)\n",
    "    elif out.strip().endswith(\"Sources:\"):\n",
    "        out += \"\\n\" + \"\\n\".join(urls)\n",
    "\n",
    "    # hallucination check: if no documents were retrieved, return a safe answer\n",
    "    if not docs:\n",
    "        out = \"I don’t know based on the official MS-ADS pages I have.\\n\\nSources:\\n( none )\"\n",
    "    # Return the model's answer text and the retrieved document list\n",
    "    return out, docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58514502-3bd2-42cb-9732-1a9d737448e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      " What are the core courses in the MS in Applied Data Science program? \n",
      "\n",
      "ANSWER:\n",
      " The core courses in the MS in Applied Data Science program include:\n",
      "\n",
      "- A total of **6 core courses** that build theoretical knowledge and practical application in data science.\n",
      "- These courses are designed to help students examine real-world business problems.\n",
      "\n",
      "Additionally, there is a **Career Seminar** (noncredit, required) that supports the development of professional skills.\n",
      "\n",
      "Sources:\n",
      "- https://datascience.uchicago.edu/education/masters-programs/online-program/\n",
      "- https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/course-progressions/ \n",
      "\n",
      "SOURCES USED:\n",
      " - https://datascience.uchicago.edu/education/masters-programs/online-program/\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/course-progressions/\n",
      " - https://datascience.uchicago.edu/education/masters-programs/in-person-program/\n"
     ]
    }
   ],
   "source": [
    "# test cell for RAG pipeline\n",
    "\n",
    "# Define a question to test\n",
    "test_question = \"What are the core courses in the MS in Applied Data Science program?\"\n",
    "\n",
    "# Run it through your answer() helper\n",
    "try:\n",
    "    answer_text, retrieved_docs = answer(test_question)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"RAG pipeline error: {e}\")\n",
    "\n",
    "# Show the answer\n",
    "print(\"QUESTION:\\n\", test_question, \"\\n\")\n",
    "print(\"ANSWER:\\n\", answer_text, \"\\n\")\n",
    "\n",
    "# 4) Summarize retrieved sources\n",
    "unique_sources = []\n",
    "seen = set()\n",
    "for d in retrieved_docs:\n",
    "    src = d.metadata.get(\"source\", \"\")\n",
    "    if src and src not in seen:\n",
    "        seen.add(src)\n",
    "        unique_sources.append(src)\n",
    "\n",
    "print(\"SOURCES USED:\")\n",
    "for s in unique_sources:\n",
    "    print(\" -\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a72ebff-1e28-4612-b3f6-3c2fe5a9ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      " who are the faculties? \n",
      "\n",
      "ANSWER:\n",
      " The faculty and staff for the MS in Applied Data Science program at the University of Chicago include:\n",
      "\n",
      "- **Greg Green**: Senior Instructional Professor; Senior Director of the DSI Polsky Transform Initiative; Senior Director of DSI Executive and Professional Education\n",
      "- **Arnab Bose, PhD**: Faculty member (specific role not detailed)\n",
      "- **Kristin McCann, PhD**: Chief of Staff, Executive Director, MS in Applied Data Science\n",
      "- **Alison Ossyra**: Director, External Partnerships and Career Services, MS in Applied Data Science\n",
      "- **DuJuan Smith, PhD**: Director, Student Affairs, MS in Applied Data Science\n",
      "- **Brody Tate, EdD**: Program Manager, Online, MS in Applied Data Science\n",
      "- **Daniel Truesdale, MPP**: Director, Enrollment Management and Analytics, MS in Applied Data Science\n",
      "- **Taylor Wallace, MEd**: Graduate Academic Advisor, MS in Applied Data Science\n",
      "- **Samantha Widemon, MNA**: Graduate Academic Advisor, MS in Applied Data Science\n",
      "- **Jennifer Wei, MEM**: Assistant Director, Career Services, MS in Applied Data Science\n",
      "- **Patrick Vonesh**: Senior Assistant Director, Enrollment Management, MS in Applied Data Science\n",
      "- **Henry Igunbor**: Senior Manager of Facilities and IT\n",
      "- **Kendall Cox**: Operations Coordinator\n",
      "- **Zach Brown**: Operations Coordinator\n",
      "\n",
      "Sources:\n",
      "- https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/ \n",
      "\n",
      "SOURCES USED:\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/faqs/\n"
     ]
    }
   ],
   "source": [
    "# test cell for RAG pipeline\n",
    "\n",
    "# Define a question to test\n",
    "test_question = \"who are the faculties?\"\n",
    "\n",
    "# Run it through your answer() helper\n",
    "try:\n",
    "    answer_text, retrieved_docs = answer(test_question)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"RAG pipeline error: {e}\")\n",
    "\n",
    "# Show the answer\n",
    "print(\"QUESTION:\\n\", test_question, \"\\n\")\n",
    "print(\"ANSWER:\\n\", answer_text, \"\\n\")\n",
    "\n",
    "# 4) Summarize retrieved sources\n",
    "unique_sources = []\n",
    "seen = set()\n",
    "for d in retrieved_docs:\n",
    "    src = d.metadata.get(\"source\", \"\")\n",
    "    if src and src not in seen:\n",
    "        seen.add(src)\n",
    "        unique_sources.append(src)\n",
    "\n",
    "print(\"SOURCES USED:\")\n",
    "for s in unique_sources:\n",
    "    print(\" -\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28d321c1-3995-4923-b213-8a544054dc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      " Can you provide information about the capstone project? \n",
      "\n",
      "ANSWER:\n",
      " - The Capstone Project is the culminating experience of the MS in Applied Data Science program.\n",
      "- Students will work on real business problems, gaining valuable insights using authentic data.\n",
      "- Collaboration with project sponsors is key to developing data science solutions that address organizational challenges.\n",
      "- There is an option to join a research-focused team, leveraging the university's research portfolio.\n",
      "- The Capstone experience enhances collaboration skills, provides mentoring, and offers networking opportunities across various sectors, including finance and entertainment.\n",
      "\n",
      "Sources:\n",
      "- https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/capstone-projects/\n",
      "- https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/ \n",
      "\n",
      "SOURCES USED:\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/capstone-projects/\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/faqs/\n"
     ]
    }
   ],
   "source": [
    "# test cell for RAG pipeline\n",
    "\n",
    "# Define a question to test\n",
    "test_question = \"Can you provide information about the capstone project?\"\n",
    "\n",
    "# Run it through your answer() helper\n",
    "try:\n",
    "    answer_text, retrieved_docs = answer(test_question)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"RAG pipeline error: {e}\")\n",
    "\n",
    "# Show the answer\n",
    "print(\"QUESTION:\\n\", test_question, \"\\n\")\n",
    "print(\"ANSWER:\\n\", answer_text, \"\\n\")\n",
    "\n",
    "# 4) Summarize retrieved sources\n",
    "unique_sources = []\n",
    "seen = set()\n",
    "for d in retrieved_docs:\n",
    "    src = d.metadata.get(\"source\", \"\")\n",
    "    if src and src not in seen:\n",
    "        seen.add(src)\n",
    "        unique_sources.append(src)\n",
    "\n",
    "print(\"SOURCES USED:\")\n",
    "for s in unique_sources:\n",
    "    print(\" -\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d72eedff-f30b-47ec-b1d6-0a37b158fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      " Are there opportunities to work with real-world datasets or industry partners? \n",
      "\n",
      "ANSWER:\n",
      " Yes, there are opportunities to work with real-world datasets and industry partners through the Capstone Experience in the MS in Applied Data Science program. This experience allows students to help top companies across multiple sectors solve real business problems. \n",
      "\n",
      "Sources:\n",
      "- https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\n",
      "- https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/events-deadlines/ \n",
      "\n",
      "SOURCES USED:\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/events-deadlines/\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\n",
      " - https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/faqs/\n"
     ]
    }
   ],
   "source": [
    "# test cell for RAG pipeline\n",
    "\n",
    "# Define a question to test\n",
    "test_question = \"Are there opportunities to work with real-world datasets or industry partners?\"\n",
    "\n",
    "# Run it through your answer() helper\n",
    "try:\n",
    "    answer_text, retrieved_docs = answer(test_question)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"RAG pipeline error: {e}\")\n",
    "\n",
    "# Show the answer\n",
    "print(\"QUESTION:\\n\", test_question, \"\\n\")\n",
    "print(\"ANSWER:\\n\", answer_text, \"\\n\")\n",
    "\n",
    "# 4) Summarize retrieved sources\n",
    "unique_sources = []\n",
    "seen = set()\n",
    "for d in retrieved_docs:\n",
    "    src = d.metadata.get(\"source\", \"\")\n",
    "    if src and src not in seen:\n",
    "        seen.add(src)\n",
    "        unique_sources.append(src)\n",
    "\n",
    "print(\"SOURCES USED:\")\n",
    "for s in unique_sources:\n",
    "    print(\" -\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a5b3b-aedd-4f99-9785-c56a931ec966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
